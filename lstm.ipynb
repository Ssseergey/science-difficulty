{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c3a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a500cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"filled/transact_18_22.csv\")\n",
    "df.set_index(['client', 'date'], inplace=True)\n",
    "df.index = df.index.set_levels(pd.to_datetime(df.index.levels[1]), level=1)\n",
    "df = df.sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18557a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_per_feature(df: pd.DataFrame, client_level: str | int = 0, date_level: str | int = 1, train_size: int = 180) -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for client, group in df.groupby(level=client_level):\n",
    "        group = group.sort_index(level=date_level)\n",
    "\n",
    "        row = {\"client\": client}\n",
    "\n",
    "        for col in group.columns:\n",
    "            values = group[col].to_numpy()\n",
    "\n",
    "            row[f\"{col}__train\"] = values[:train_size]\n",
    "            row[f\"{col}__test\"] = values[train_size:]\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    result_df = pd.DataFrame(rows).set_index(\"client\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e86aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df = split_train_test_per_feature(df)\n",
    "parsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d6110",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df = parsed_df[[\"survival__train\", \"socialization__train\", \"self_realization__train\", \"survival__test\", \"socialization__test\", \"self_realization__test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633df304",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "n_predictions = 120\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5122a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windows(series, input_len=30, horizon=7):\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - input_len - horizon + 1):\n",
    "        X.append(series[i : i + input_len])\n",
    "        y.append(series[i + input_len : i + input_len + horizon])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "class LSTMForecast(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=1, hidden_size=29, batch_first=True)\n",
    "        # self.dropout = nn.Dropout(0.3)\n",
    "        self.lstm2 = nn.LSTM(input_size=29, hidden_size=15, batch_first=True)\n",
    "        self.fc1 = nn.Linear(15, 15)\n",
    "        self.fc2 = nn.Linear(15, 7)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        # x = self.dropout(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.tanh(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88a32cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictability_from_f1(f1_df: pd.DataFrame, threshold: float = 0.75) -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for client, row in f1_df.iterrows():\n",
    "        res = {\"client\": client}\n",
    "        hp_values = []\n",
    "\n",
    "        for feature, f1_scores in row.items():\n",
    "            if f1_scores is None or len(f1_scores) == 0:\n",
    "                hp = np.nan\n",
    "            else:\n",
    "                hp = (np.asarray(f1_scores) > threshold).mean()\n",
    "\n",
    "            res[f\"{feature}_HP\"] = hp\n",
    "\n",
    "            if not np.isnan(hp):\n",
    "                hp_values.append(hp)\n",
    "\n",
    "        if len(hp_values) > 0:\n",
    "            res[\"predictability\"] = (\n",
    "                np.linalg.norm(hp_values) / np.sqrt(len(hp_values))\n",
    "            )\n",
    "        else:\n",
    "            res[\"predictability\"] = np.nan\n",
    "\n",
    "        rows.append(res)\n",
    "\n",
    "    return pd.DataFrame(rows).set_index(\"client\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c87665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].unsqueeze(-1), self.y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c2a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_global_model_for_feature(df, feature, batch_size=1024):\n",
    "    train_cols = f\"{feature}__train\"\n",
    "    test_cols = f\"{feature}__test\"\n",
    "\n",
    "    X_train_all, y_train_all = [], []\n",
    "    X_val_all, y_val_all = [], []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        train_series = row[train_cols]\n",
    "        X_train, y_train = make_windows(train_series)\n",
    "        X_train_all.append(X_train)\n",
    "        y_train_all.append(y_train)\n",
    "\n",
    "        test_series = row[test_cols]\n",
    "        X_val, y_val = make_windows(test_series)\n",
    "        X_val_all.append(X_val)\n",
    "        y_val_all.append(y_val)\n",
    "\n",
    "    X_train_all = np.concatenate(X_train_all)\n",
    "    y_train_all = np.concatenate(y_train_all)\n",
    "    X_val_all = np.concatenate(X_val_all)\n",
    "    y_val_all = np.concatenate(y_val_all)\n",
    "\n",
    "    train_dataset = TimeSeriesDataset(X_train_all, y_train_all)\n",
    "    val_dataset = TimeSeriesDataset(X_val_all, y_val_all)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = LSTMForecast().to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-3) # , weight_decay=1e-4\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        for X_batch, y_batch in loop:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_batch)\n",
    "\n",
    "            batch_pos = y_batch.mean().clamp(min=1e-3)\n",
    "            pos_weight_batch = (1 - batch_pos) / batch_pos\n",
    "            loss_fn = nn.BCEWithLogitsLoss(\n",
    "                pos_weight=pos_weight_batch.detach(),\n",
    "                reduction=\"mean\"\n",
    "            )\n",
    "\n",
    "            loss = loss_fn(preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_train_loss += loss.item() * X_batch.size(0)\n",
    "            loop.set_postfix({\"batch_loss\": loss.item()})\n",
    "\n",
    "        epoch_train_loss /= len(train_dataset)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                preds = model(X_batch)\n",
    "                loss = loss_fn(preds, y_batch)\n",
    "                epoch_val_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "        epoch_val_loss /= len(val_dataset)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {epoch_train_loss:.4f}, Val Loss: {epoch_val_loss:.4f}\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, epochs+1), train_losses, marker='o', label=\"Train Loss\")\n",
    "    plt.plot(range(1, epochs+1), val_losses, marker='x', label=\"Validation Loss\")\n",
    "    plt.title(f\"Loss per Epoch for feature: {feature}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"BCELoss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_and_f1_for_client(model, test_series):\n",
    "    X_test, y_test = make_windows(test_series)\n",
    "\n",
    "    if len(X_test) < n_predictions:\n",
    "        print(\"Warning:\", len(X_test), \"<\", n_predictions)\n",
    "\n",
    "    X_test = X_test[:n_predictions]\n",
    "    y_test = y_test[:n_predictions]\n",
    "\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32, device=device).unsqueeze(-1)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_test).cpu()\n",
    "        probs = torch.sigmoid(preds).numpy()\n",
    "\n",
    "    preds_bin = (probs > 0.5).astype(int)\n",
    "\n",
    "    f1_scores = np.array([\n",
    "        f1_score(y_test[i], preds_bin[i], zero_division=0)\n",
    "        for i in range(len(preds_bin))\n",
    "    ])\n",
    "\n",
    "    return f1_scores\n",
    "\n",
    "def train_lstm_and_compute_f1(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    features = [c.replace(\"__train\", \"\") for c in df.columns if c.endswith(\"__train\")]\n",
    "\n",
    "    results = {\n",
    "        client: {\"client\": client}\n",
    "        for client in df.index\n",
    "    }\n",
    "\n",
    "    for feature in features:\n",
    "        print(f\"Training global model for feature: {feature}\")\n",
    "        model = train_global_model_for_feature(df, feature)\n",
    "\n",
    "        for client, row in df.iterrows():\n",
    "            test_series = row[f\"{feature}__test\"]\n",
    "            f1_scores = predict_and_f1_for_client(model, test_series)\n",
    "            results[client][feature] = f1_scores\n",
    "\n",
    "    return pd.DataFrame(results.values()).set_index(\"client\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab415c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = train_lstm_and_compute_f1(parsed_df)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8c0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictability_from_f1(f1_df: pd.DataFrame, threshold: float = 0.5) -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for client, row in f1_df.iterrows():\n",
    "        res = {\"client\": client}\n",
    "        hp_values = []\n",
    "\n",
    "        for feature, f1_scores in row.items():\n",
    "            if f1_scores is None or len(f1_scores) == 0:\n",
    "                hp = np.nan\n",
    "            else:\n",
    "                hp = (np.asarray(f1_scores) > threshold).mean()\n",
    "\n",
    "            res[f\"{feature}_HP\"] = hp\n",
    "\n",
    "            if not np.isnan(hp):\n",
    "                hp_values.append(hp)\n",
    "\n",
    "        if len(hp_values) > 0:\n",
    "            res[\"predictability\"] = (\n",
    "                np.linalg.norm(hp_values) / np.sqrt(len(hp_values))\n",
    "            )\n",
    "        else:\n",
    "            res[\"predictability\"] = np.nan\n",
    "\n",
    "        rows.append(res)\n",
    "\n",
    "    return pd.DataFrame(rows).set_index(\"client\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictability = compute_predictability_from_f1(res)\n",
    "predictability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683dc067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_number_of_customers_by_hit_probability(df, hit_prob_col=\"hit_probability\", bins=20):\n",
    "    hit_probs = df[hit_prob_col].dropna().values\n",
    "\n",
    "    counts, bin_edges = np.histogram(hit_probs, bins=bins)\n",
    "\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(bin_centers, counts, width=(bin_edges[1] - bin_edges[0]) * 0.9)\n",
    "    plt.xlabel(\"Hit probability\")\n",
    "    plt.ylabel(\"Number of customers\")\n",
    "    plt.title(\"Number of customers by hit probability\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6908177",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_number_of_customers_by_hit_probability(predictability, hit_prob_col=\"survival_HP\", bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207de780",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_number_of_customers_by_hit_probability(predictability, hit_prob_col=\"socialization_HP\", bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763695eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_number_of_customers_by_hit_probability(predictability, hit_prob_col=\"self_realization_HP\", bins=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
